{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S-NN upload",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4mOWyjrkqvKJpcL07ykYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sblHead/Supplementary-code/blob/main/S_NN_upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT0vX5teaRG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b8e9d8-ffd2-40e7-b07c-1f672e95e62f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import csv\n",
        "import sklearn\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/')    # if importing data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = 6\n",
        "Xdata = []\n",
        "\n",
        "with open('', newline = '\\n') as csvfile:            # Read in material data file\n",
        "  data = csv.reader(csvfile, delimiter = ',')\n",
        "  for row in data:\n",
        "    row = np.array(row)\n",
        "    row =  row.astype(np.float)\n",
        "    Xdata.append(row)\n",
        "    \n",
        "Xdata = np.delete(Xdata,slice(0,len(Xdata),2),axis = 0)\n",
        "\n",
        "Ydata = []\n",
        "with open('', newline = '\\n') as csvfile:       # Read in spectral response data file\n",
        "  data = csv.reader(csvfile, delimiter = ',')\n",
        "  for row in data:\n",
        "    row = np.array(row)\n",
        "    row =  row.astype(np.float)\n",
        "    Ydata.append(row)\n",
        "Ydata = np.transpose(Ydata)\n",
        "Ydata = np.delete(Ydata,slice(0,len(Ydata),2),axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "print(np.shape(Xdata))       # ensure that each row is a new sample, i.e. shape = (num samples, len sample)\n",
        "print(np.shape(Ydata))"
      ],
      "metadata": {
        "id": "nNLbU2ClaSOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = 40\n",
        "\n",
        "\n",
        "XTrain = []\n",
        "YTrain = []\n",
        "XTest = []\n",
        "YTest = []\n",
        "XNew = []\n",
        "YNew = []\n",
        "\n",
        "XShuff, YShuff = sklearn.utils.shuffle(Xdata, Ydata)\n",
        "\n",
        "XTrain = XShuff[:18000]\n",
        "YTrain = YShuff[:18000]\n",
        "XTest = XShuff[18000:21000]\n",
        "YTest = YShuff[18000:21000]\n",
        "XNew = XShuff[21000:]\n",
        "YNew = YShuff[21000:]\n",
        "\n",
        "XTrain = np.array(XTrain)\n",
        "YTrain = np.array(YTrain)\n",
        "XTest = np.array(XTest)\n",
        "YTest = np.array(YTest)"
      ],
      "metadata": {
        "id": "gciofcg_A9E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_tensor = keras.Input(shape = (input_shape))\n",
        "input_tensor= keras.layers.BatchNormalization(axis=-1)(input_tensor)\n",
        "\n",
        "x = keras.layers.Dense(500, activation = None)(input_tensor)\n",
        "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = keras.layers.Dropout(0.02)(x)\n",
        "\n",
        "\n",
        "x = keras.layers.Dense(500, activation = None)(x)\n",
        "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "x = keras.layers.Dropout(0.01)(x)\n",
        "\n",
        "\n",
        "x = keras.layers.Dense(500, activation = None)(x)\n",
        "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\n",
        "\n",
        "x = keras.layers.Dense(1000, activation = None)(x)\n",
        "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "\n",
        "output_tensor = keras.layers.Dense(81, activation = 'relu')(x)\n",
        "\n",
        "model = keras.models.Model(input_tensor, output_tensor)\n",
        "\n",
        "model.compile(loss = keras.losses.MeanSquaredError(),\n",
        "              optimizer = 'Adam',\n",
        "              metrics = ['mean_absolute_error'])\n",
        "\n",
        "\n",
        "callback_list = [keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=4, min_lr=1e-6), \n",
        "                 keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(XTrain, YTrain, epochs = epoch_num, callbacks = callback_list, validation_data = (XTest, YTest),verbose =1)\n",
        "\n",
        "#model.summary()\n",
        "#print(model.evaluate(XNew,YNew,verbose = 0))"
      ],
      "metadata": {
        "id": "k-EmgOMAaenH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.evaluate(XNew,YNew,verbose = 0))"
      ],
      "metadata": {
        "id": "B55Fcns0i8tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('')      # Save model to desire location"
      ],
      "metadata": {
        "id": "7i8YuiqYfbDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IhnLrjSSahrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['mean_absolute_error']         # Produces a learning curve graph showing training and validation curves\n",
        "loss_val = history.history['val_mean_absolute_error']\n",
        "epochs = range(1,40)\n",
        "plt.figure(figsize = (3.5,3.5),dpi=1200)\n",
        "plt.plot(epochs, loss_train[1:], 'g', label='Training MSE')\n",
        "plt.plot(epochs, loss_val[1:], 'b', label='Validation MSE')\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Mean Absolute Error',fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BX9f0zeRakU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = ##                                                    # produces a graph comparing target and predicted spectra     \n",
        "Y_hat = model.predict(XNew[num].reshape(-1,6))\n",
        "Y_acc = YNew[num].reshape(81, -1)\n",
        "Y_hat = np.transpose(Y_hat)\n",
        "spectrum_wav = np.arange(380, 781, 5)\n",
        "# plt.figure(figsize = (3.5,3.5),dpi=1200)\n",
        "plt.plot(spectrum_wav, Y_hat, 'b')\n",
        "plt.plot(spectrum_wav, Y_acc, 'r')\n",
        "plt.ylim([0, 1])\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.xlabel('Wavelength, nm', fontsize=16)\n",
        "plt.ylabel('Reflectance coefficient',fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxnDjIzEamWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}